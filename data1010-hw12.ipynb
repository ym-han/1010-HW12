{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Homework 12\n",
        "\n",
        "#### *DATA 1010*"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import Pkg; Pkg.activate(\".\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\u001b[1mActivating\u001b[22m\u001b[39m environment at `~/Google Drive/DSI/Masters Program/DATA 1010/DATA1010-2019/problem-sets/hw12/Project.toml`\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "using Random, CSV, Turing, Distributions, MCMCChains, Plots, StatsPlots, StatsFuns\n",
        "Turing.turnprogress(false);\n",
        "Random.seed!(123);"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "┌ Info: [Turing]: global PROGRESS is set as false\n",
            "└ @ Turing /Users/sswatson/.julia/packages/Turing/xFzfF/src/Turing.jl:23\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Problem 1\n",
        "\n",
        "Consider two probability density functions, $f_1(x)$ and $f_2(x)$. Assume that we have $N$ observations $x_1,\\cdots,x_N$ drawn from a mixture of these **known** densities:\n",
        "$$ \\pi f_1(x) + (1-\\pi) f_2(x) $$\n",
        "Write down the E and M steps you would use to estimate the proportion $\\pi$, given the dataset.\n",
        "\n",
        "*Hint*: Use a hidden state variable $z_i$ to indicate that data point $x_i$ belongs to $f_1$."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2 (Bayesian Logistic Regression)\n",
        "\n",
        "Recall logistic regression, where we find coefficients $\\mathbf{\\beta}, \\alpha$ to predict label the $y_i$ given input features $\\mathbf{x_i}$:\n",
        "$$ \\mathbb{P}(y_i = 1|\\mathbf{x_i}) = \\sigma(\\boldsymbol{\\beta}'\\mathbf{x_i} + \\alpha)$$\n",
        "\n",
        "Here, we develop the Bayesian counterpart to obtain the full posterior over the coefficients: $\\mathbb{P}(\\mathbf{\\beta}|\\mathcal{D})$, where data $\\mathcal{D}$ consists of all training observations. Unlike linear regression, there is no convenient conjugate prior for logistic regression, so we use MCMC with `Turing.jl`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "grad_data = CSV.read(\"grad_admission.csv\")\n",
        "first(grad_data, 6)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/html": [
              "<table class=\"data-frame\"><thead><tr><th></th><th>admit</th><th>gre</th><th>gpa</th><th>rank</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Float64</th><th>Int64</th></tr></thead><tbody><p>6 rows × 4 columns</p><tr><th>1</th><td>0</td><td>380</td><td>3.61</td><td>3</td></tr><tr><th>2</th><td>1</td><td>660</td><td>3.67</td><td>3</td></tr><tr><th>3</th><td>1</td><td>800</td><td>4.0</td><td>1</td></tr><tr><th>4</th><td>1</td><td>640</td><td>3.19</td><td>4</td></tr><tr><th>5</th><td>0</td><td>520</td><td>2.93</td><td>4</td></tr><tr><th>6</th><td>1</td><td>760</td><td>3.0</td><td>2</td></tr></tbody></table>"
            ],
            "text/latex": [
              "\\begin{tabular}{r|cccc}\n",
              "\t& admit & gre & gpa & rank\\\\\n",
              "\t\\hline\n",
              "\t& Int64 & Int64 & Float64 & Int64\\\\\n",
              "\t\\hline\n",
              "\t1 & 0 & 380 & 3.61 & 3 \\\\\n",
              "\t2 & 1 & 660 & 3.67 & 3 \\\\\n",
              "\t3 & 1 & 800 & 4.0 & 1 \\\\\n",
              "\t4 & 1 & 640 & 3.19 & 4 \\\\\n",
              "\t5 & 0 & 520 & 2.93 & 4 \\\\\n",
              "\t6 & 1 & 760 & 3.0 & 2 \\\\\n",
              "\\end{tabular}\n"
            ],
            "text/plain": [
              "6×4 DataFrame\n",
              "│ Row │ admit │ gre   │ gpa     │ rank  │\n",
              "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n",
              "├─────┼───────┼───────┼─────────┼───────┤\n",
              "│ 1   │ 0     │ 380   │ 3.61    │ 3     │\n",
              "│ 2   │ 1     │ 660   │ 3.67    │ 3     │\n",
              "│ 3   │ 1     │ 800   │ 4.0     │ 1     │\n",
              "│ 4   │ 1     │ 640   │ 3.19    │ 4     │\n",
              "│ 5   │ 0     │ 520   │ 2.93    │ 4     │\n",
              "│ 6   │ 1     │ 760   │ 3.0     │ 2     │"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "grad_data.gre = (grad_data.gre .- mean(grad_data.gre)) ./ std(grad_data.gre)\n",
        "grad_data.gpa = (grad_data.gpa .- mean(grad_data.gpa)) ./ std(grad_data.gpa)\n",
        "\n",
        "grad_data = grad_data[shuffle(1:size(grad_data, 1)),:];\n",
        "\n",
        "train_test_split_index = Int(round(size(grad_data, 1) * 0.7))\n",
        "train = grad_data[1:train_test_split_index, :]\n",
        "test = grad_data[(train_test_split_index+1):end, :]\n",
        "\n",
        "train_label = train[:,:admit];\n",
        "test_label = test[:,:admit];\n",
        "\n",
        "train = train[:,[:gre, :gpa, :rank]];\n",
        "test = test[:,[:gre, :gpa, :rank]];"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Turing.jl model called `logistic_regression` which gives priors of $N(0, \\sigma)$ to `intercept`, `gre`, `gpa`, and `rank`. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "@model logistic_regression(x, y, n, σ) = begin\n",
        "    \n",
        "\n",
        "end;"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the number of observations.\n",
        "n = size(train, 1)\n",
        "\n",
        "# Sample using HMC\n",
        "chain = mapreduce(c -> sample(logistic_regression(train, train_label, n, 1), HMC(0.05, 10), 1500),\n",
        "    chainscat,\n",
        "    1:3\n",
        ")\n",
        "\n",
        "describe(chain)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": [
              "2-element Array{ChainDataFrame,1}\n",
              "\n",
              "Summary Statistics\n",
              ". Omitted printing of 1 columns\n",
              "│ Row │ parameters │ mean     │ std       │ naive_se    │ mcse       │ ess     │\n",
              "│     │ \u001b[90mSymbol\u001b[39m     │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mAny\u001b[39m     │\n",
              "├─────┼────────────┼──────────┼───────────┼─────────────┼────────────┼─────────┤\n",
              "│ 1   │ gpa        │ 0.321881 │ 0.356509  │ 0.00531453  │ 0.0534671  │ 18.0723 │\n",
              "│ 2   │ gre        │ 0.59765  │ 0.0950642 │ 0.00141713  │ 0.0111314  │ 18.0723 │\n",
              "│ 3   │ intercept  │ 2.65669  │ 0.130045  │ 0.0019386   │ 0.0169787  │ 18.0723 │\n",
              "│ 4   │ rank       │ 0.269729 │ 0.0652298 │ 0.000972388 │ 0.00895466 │ 18.0723 │\n",
              "\n",
              "Quantiles\n",
              "\n",
              "│ Row │ parameters │ 2.5%      │ 25.0%     │ 50.0%    │ 75.0%    │ 97.5%    │\n",
              "│     │ \u001b[90mSymbol\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m  │\n",
              "├─────┼────────────┼───────────┼───────────┼──────────┼──────────┼──────────┤\n",
              "│ 1   │ gpa        │ -0.160595 │ -0.160595 │ 0.445086 │ 0.688054 │ 0.688054 │\n",
              "│ 2   │ gre        │ 0.515744  │ 0.515744  │ 0.570257 │ 0.689438 │ 0.689438 │\n",
              "│ 3   │ intercept  │ 2.51657   │ 2.51657   │ 2.67181  │ 2.79141  │ 2.79141  │\n",
              "│ 4   │ rank       │ 0.201209  │ 0.201209  │ 0.256444 │ 0.346412 │ 0.346412 │\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Problem 3 (Simpson’s Paradox)\n",
        "\n",
        "Consider the following classic example given by Edward Simpson in 1951.\n",
        "\n",
        "700 patients were given access to a drug the effectiveness of which we would like to study. A total of 350 patients chose to take the drug and 350 didn’t. The result is given below:\n",
        "\n",
        "|Categories            | Drug                           | No Drug   |\n",
        "|---------------    |---------------------|--------------------------------|\n",
        "| Men           | 81 out of 87 (93%)             | 234 out of 270 recovered (87%) |   \n",
        "| Women         | 192 out of 263 recovered (73%) | 55 out of 80 recovered (69%)   |\n",
        "| Combined data | 273 out of 350 recovered (78%) | 289 out of 350 recovered (83%) |\n",
        "\n",
        "(a) Not controlling for sex, describe the overall trend of taking the drug.\n",
        "\n",
        "(b) Describe the overall trend of taking the drug conditioned on sex.\n",
        "\n",
        "(c) Match the following English sentences to its corresponding mathematical statement in the list below. Note that one of the mathematical statements will not have a match. Here men are $Z=0$, women are $Z=1$, non-recovery is $Y=0$, and recovery is $Y=1$, and non-treatment is $X=0$ and treatment is $X=1$.\n",
        "\n",
        "(i) The drug is beneficial for men.  \n",
        "(ii) The drug is beneficial for women.  \n",
        "(iii) The drug is beneficial overall.\n",
        "\n",
        "(I) $\\mathbb{P}(Y=1 | X=1) > \\mathbb{P}(Y=1 | X=0)$  \n",
        "(II) $\\mathbb{P}(C_1 = 1) > \\mathbb{P}(C_1 = 0)$  \n",
        "(III) $\\mathbb{P}(C_1 = 1 | Z = 1) > \\mathbb{P}(C_1 = 0 | Z = 1)$  \n",
        "(IV) $\\mathbb{P}(C_1 = 1 | Z = 0) > \\mathbb{P}(C_1 = 0 | Z = 0)$\n",
        "\n",
        "(d) Show mathematically that if a drug is beneficial for each subpopulation in a partition of the overall population, then it is beneficial overall. (Hint: you will want to use the formulation of \"beneficial\" from part (c). "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Problem 4\n",
        "\n",
        "Consider the following statement from an advertisement. \n",
        "\n",
        "‘In this town we observe that those who take soy isoflavone supplements have improved cognitive performance. Thus, for anyone looking to improve their cognitive performance, they should consider taking soy isoflavone.’\n",
        "\n",
        "Identify the problematic causal inference in this statement. Identify whether each statement strengthens or weakens the claim (or neither).\n",
        "\n",
        "\n",
        "a) The alleged cause and effect are both effects of some common cause.\n",
        "\n",
        "b) The cause and effect are flipped; the alleged cause is the effect and vice versa.\n",
        "\n",
        "c) The presence of the cause in a relatively large population does not coincide with the detection of the effect. \n",
        "\n",
        "d) The presence of the effect has been identified in a large population but not the cause.\n",
        "\n",
        "e) A possible confounder for this effect has been ruled out."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Problem 5\n",
        "\n",
        "Suppose we want to evaluate the impact of the National Supported Work (NSW) Demonstration, a labor training program on real earnings in 1978. Our dataset, from [LaLonde (1986)](https://www.jstor.org/stable/1806062), consists of measurements of age, years of schooling, ethnicity, marital status and earnings."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "la_londe = CSV.read(\"lalonde.csv\")\n",
        "la_londe = la_londe[shuffle(1:size(la_londe, 1)),:];\n",
        "first(la_londe, 6)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/html": [
              "<table class=\"data-frame\"><thead><tr><th></th><th>data_id</th><th>treat</th><th>age</th><th>education</th><th>black</th><th>hispanic</th><th>married</th><th>nodegree</th><th>re75</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Float64</th></tr></thead><tbody><p>6 rows × 10 columns (omitted printing of 1 columns)</p><tr><th>1</th><td>Lalonde Sample</td><td>0</td><td>18</td><td>9</td><td>0</td><td>1</td><td>0</td><td>1</td><td>2684.91</td></tr><tr><th>2</th><td>Lalonde Sample</td><td>0</td><td>33</td><td>11</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0.0</td></tr><tr><th>3</th><td>Lalonde Sample</td><td>0</td><td>19</td><td>9</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1537.93</td></tr><tr><th>4</th><td>Lalonde Sample</td><td>0</td><td>20</td><td>9</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0.0</td></tr><tr><th>5</th><td>Lalonde Sample</td><td>1</td><td>46</td><td>8</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0.0</td></tr><tr><th>6</th><td>Lalonde Sample</td><td>1</td><td>31</td><td>13</td><td>0</td><td>0</td><td>0</td><td>0</td><td>5498.35</td></tr></tbody></table>"
            ],
            "text/latex": [
              "\\begin{tabular}{r|cccccccccc}\n",
              "\t& data\\_id & treat & age & education & black & hispanic & married & nodegree & re75 & \\\\\n",
              "\t\\hline\n",
              "\t& String & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Float64 & \\\\\n",
              "\t\\hline\n",
              "\t1 & Lalonde Sample & 0 & 18 & 9 & 0 & 1 & 0 & 1 & 2684.91 & $\\dots$ \\\\\n",
              "\t2 & Lalonde Sample & 0 & 33 & 11 & 1 & 0 & 0 & 1 & 0.0 & $\\dots$ \\\\\n",
              "\t3 & Lalonde Sample & 0 & 19 & 9 & 1 & 0 & 0 & 1 & 1537.93 & $\\dots$ \\\\\n",
              "\t4 & Lalonde Sample & 0 & 20 & 9 & 1 & 0 & 0 & 1 & 0.0 & $\\dots$ \\\\\n",
              "\t5 & Lalonde Sample & 1 & 46 & 8 & 1 & 0 & 1 & 1 & 0.0 & $\\dots$ \\\\\n",
              "\t6 & Lalonde Sample & 1 & 31 & 13 & 0 & 0 & 0 & 0 & 5498.35 & $\\dots$ \\\\\n",
              "\\end{tabular}\n"
            ],
            "text/plain": [
              "6×10 DataFrame. Omitted printing of 4 columns\n",
              "│ Row │ data_id        │ treat │ age   │ education │ black │ hispanic │\n",
              "│     │ \u001b[90mString\u001b[39m         │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m     │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m    │\n",
              "├─────┼────────────────┼───────┼───────┼───────────┼───────┼──────────┤\n",
              "│ 1   │ Lalonde Sample │ 0     │ 18    │ 9         │ 0     │ 1        │\n",
              "│ 2   │ Lalonde Sample │ 0     │ 33    │ 11        │ 1     │ 0        │\n",
              "│ 3   │ Lalonde Sample │ 0     │ 19    │ 9         │ 1     │ 0        │\n",
              "│ 4   │ Lalonde Sample │ 0     │ 20    │ 9         │ 1     │ 0        │\n",
              "│ 5   │ Lalonde Sample │ 1     │ 46    │ 8         │ 1     │ 0        │\n",
              "│ 6   │ Lalonde Sample │ 1     │ 31    │ 13        │ 0     │ 0        │"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Compare features (age, years of education, etc.) between individuals that received treatment (`treat = 1`) and those who are in the control group (`treat = 0`). What do you observe? What might be the confounding factors in our analysis?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "To mitigate (but not entirely eliminate) the effect of confounding factors, we can match data between treatment and control pairs as follows:\n",
        "\n",
        "i. Define a distance measure between feature vectors.\n",
        "\n",
        "ii. Select a subset from the treatment and control groups which are close.\n",
        "\n",
        "iii. Evaluate quality of matching\n",
        "\n",
        "iv. Perform analysis on the matched set.\n",
        "\n",
        "b) Consider the *Mahalanobis distance* between observations $x_i$ and $x_j$, defined as : $D_{ij} = (x_i - x_j)^T\\Sigma^{-1}(x_i - x_j)$, where $\\Sigma$ is the covariance matrix estimated from the data. Compute $D_{ij}$ using age, education and re75 (real income in 1975). "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) The *propensity score distance* is defined as $D_{ij} = |\\pi_i - \\pi_j|$, where $\\pi_i = \\mathbb{P}(\\text{treat}=1|x_i)$ is the probability of being in the treatment group for observation $x_i$. Compute propensity scores for the LaLonde dataset and extract a matching set."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "jupytext": {
      "formats": "ipynb"
    },
    "kernelspec": {
      "name": "julia-1.2",
      "language": "julia",
      "display_name": "Julia 1.2.0"
    },
    "language_info": {
      "file_extension": ".jl",
      "name": "julia",
      "mimetype": "application/julia",
      "version": "1.2.0"
    },
    "kernel_info": {
      "name": "julia-1.2"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}